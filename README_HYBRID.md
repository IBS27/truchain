# Hybrid Video Verification System

## ğŸ¯ Overview

This system verifies if a video clip is an authentic excerpt from official campaign videos using a **two-stage verification process**:

1. **CONTENT MATCHING** (Transcription + Text Similarity)
   - Transcribes the clip using OpenAI Whisper
   - Compares text semantically against database transcripts
   - Finds WHAT was said and WHERE in the original video

2. **SPEAKER VERIFICATION** (Audio Embeddings)
   - Compares voice characteristics using Wav2Vec2 embeddings
   - Verifies WHO is speaking
   - Prevents deepfakes and voiceovers

## ğŸ”’ What This Prevents

âœ… **False Positives**: Different speeches by same person (e.g., two different Fed speeches by Powell)
âœ… **Deepfakes**: Same words spoken by different voice (AI-generated speech)
âœ… **Voiceovers**: Actor reading the same transcript
âœ… **Out-of-Context Clips**: Shows exact timestamp in original video for context

## ğŸ“¦ Installation

### 1. Install Python Dependencies

```bash
pip3.10 install -r requirements.txt
```

### 2. Set OpenAI API Key

```bash
export OPENAI_API_KEY='your-api-key-here'
```

Get your API key from: https://platform.openai.com/api-keys

### 3. Verify FFmpeg Installation

```bash
ffmpeg -version
```

## ğŸš€ Quick Start

### Step 1: Process Original Videos

Process all videos in the `download/` directory:

```bash
python3.10 process_videos_hybrid.py --directory download
```

Or process a single video:

```bash
python3.10 process_videos_hybrid.py \
  --video download/fedspeech1.mp4 \
  --title "Federal Reserve Chair Speech"
```

This will:
- Transcribe the entire video (30-second segments)
- Generate audio embeddings for speaker verification
- Store everything in `video_database_hybrid.json`

**Cost**: Approximately $0.36 per hour of video (Whisper API)

### Step 2: Verify a Clip

```bash
python3.10 hybrid_verification.py test_clips/user_clip.mp4
```

Example output:

```
================================================================================
HYBRID VERIFICATION
================================================================================

Verifying clip: test_clips/user_clip.mp4

STAGE 1: Content Analysis (Transcription)
--------------------------------------------------------------------------------
Transcribing video: test_clips/user_clip.mp4
...

STAGE 2: Database Search (Text Matching)
--------------------------------------------------------------------------------
âœ“ Content match found!
  Video ID: fedspeech1.mp4
  Timestamp: 02:00 - 02:30
  Similarity: 94.2%
  Consecutive matches: 3

STAGE 3: Speaker Verification (Audio Embeddings)
--------------------------------------------------------------------------------
  Segment 1: 96.3%
  Segment 2: 95.8%
  Segment 3: 96.1%

  Average speaker similarity: 96.1%
  âœ“ Speaker verified (threshold: 90.0%)

================================================================================
FINAL VERDICT
================================================================================

  âœ“ VERIFIED with HIGH confidence. Content matches at 02:00 and speaker is verified.
```

## ğŸ“Š Understanding Results

### Verification Levels

| Confidence | Meaning |
|------------|---------|
| **HIGH** | Content similarity â‰¥85% AND speaker verified â‰¥90% AND â‰¥3 consecutive matches |
| **MEDIUM** | Content similarity â‰¥75% AND speaker verified â‰¥90% AND â‰¥2 consecutive matches |
| **LOW** | Content matches but speaker verification failed (possible deepfake) |
| **NOT VERIFIED** | Content doesn't match any video in database |

### Key Metrics

- **Content Similarity**: How well the text matches (0-100%)
- **Speaker Similarity**: How well the voice matches (0-100%)
- **Consecutive Matches**: Number of 30-second segments that match in sequence
- **Timestamp Range**: Where in the original video the clip appears

## ğŸ§ª Testing

### Run Test Suite

```bash
python3.10 test_hybrid_system.py
```

Tests include:
1. âœ… Exact clip verification (should pass with HIGH confidence)
2. âœ… Different video rejection (should be rejected)
3. âœ… Timestamp accuracy (within 30 seconds)
4. âš ï¸ Deepfake detection (conceptual - requires test video)

### Create Test Clips

```bash
# Create a 10-second exact clip from an original video
ffmpeg -i download/fedspeech1.mp4 -ss 30 -t 10 -y test_clips/exact_clip_10s.mp4

# Create a degraded quality clip
ffmpeg -i download/fedspeech1.mp4 -ss 60 -t 15 -b:a 32k -ar 16000 -y test_clips/degraded_clip.mp4
```

## ğŸ—ï¸ System Architecture

```
User Clip
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: CONTENT MATCHING                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Transcribe clip (Whisper API)               â”‚
â”‚  2. Compare text vs database transcripts         â”‚
â”‚  3. Find matching segments & timestamps          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ (If content matches)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: SPEAKER VERIFICATION                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Extract audio embeddings (Wav2Vec2)          â”‚
â”‚  2. Compare voice characteristics                â”‚
â”‚  3. Verify same speaker                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VERDICT                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ“ HIGH: Both content & speaker match           â”‚
â”‚  âš  MEDIUM: Good content match, speaker verified  â”‚
â”‚  âš  LOW: Content matches but speaker doesn't     â”‚
â”‚  âœ— NOT VERIFIED: Content doesn't match          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Key Files

| File | Purpose |
|------|---------|
| `audio_transcription.py` | Transcribes videos using Whisper API |
| `text_matching.py` | Semantic text comparison using sentence-transformers |
| `audio_embedding.py` | Speaker verification using Wav2Vec2 |
| `hybrid_verification.py` | Main verification pipeline |
| `process_videos_hybrid.py` | Process videos for database |
| `video_database_hybrid.json` | Database with transcripts + embeddings |
| `test_hybrid_system.py` | Test suite |

## ğŸ”§ Configuration

### Adjust Thresholds

Edit `hybrid_verification.py`:

```python
class HybridVerifier:
    TEXT_SIMILARITY_THRESHOLD = 0.75      # Content match threshold (75%)
    SPEAKER_SIMILARITY_THRESHOLD = 0.90    # Speaker match threshold (90%)
    MIN_CONSECUTIVE_MATCHES = 2            # Minimum segments to match
```

### Use Local Whisper (No API Cost)

Replace `audio_transcription.py` to use `whisper` library instead of OpenAI API:

```bash
pip3.10 install openai-whisper
```

Then modify the transcription code to use local model (slower but free).

## ğŸ“ˆ Performance

| Operation | Time | Cost |
|-----------|------|------|
| Process 1 hour video | ~5-10 min | $0.36 (Whisper API) |
| Verify 30-second clip | ~3-8 seconds | $0.018 (Whisper API) |
| Verify with local Whisper | ~10-30 seconds | Free |

## ğŸ“ How It Works

### Content Matching (Text-Based)

1. **Transcription**: Converts audio to text using state-of-the-art Whisper model
2. **Semantic Similarity**: Uses sentence-transformers to compare meaning (not just exact words)
   - "The Fed decided to keep rates unchanged" â‰ˆ "Federal Reserve maintains current interest rates"
   - Similarity: ~85%
3. **Sequential Matching**: Finds consecutive matching segments for accuracy
4. **Timestamp Detection**: Returns exact position in original video

### Speaker Verification (Voice-Based)

1. **Audio Embeddings**: Wav2Vec2 extracts voice characteristics
   - Pitch, tone, speaking style, acoustic patterns
2. **Cosine Similarity**: Compares embedding vectors
3. **Threshold Check**: Verifies similarity â‰¥90%

### Why Both Are Needed

| Attack Type | Content Match | Speaker Match | Result |
|-------------|---------------|---------------|---------|
| Different speech (same person) | âŒ Low | âœ… High | Rejected |
| Deepfake (same words, AI voice) | âœ… High | âŒ Low | Rejected |
| Authentic clip | âœ… High | âœ… High | âœ… Verified |
| Different person, different content | âŒ Low | âŒ Low | Rejected |

## ğŸš¨ Limitations

1. **Heavy Editing**: Clips heavily edited with music/effects may fail speaker verification
2. **Very Short Clips**: < 10 seconds may not have enough consecutive matches
3. **Background Noise**: Very noisy audio may reduce transcription accuracy
4. **Cost**: Using OpenAI API costs ~$0.018 per 30-second clip verification

## ğŸ”® Future Improvements

1. **Local Whisper**: Use local model to eliminate API costs
2. **Blockchain Integration**: Store hashes on actual blockchain (Ethereum, Polygon)
3. **IPFS Integration**: Upload and retrieve videos from IPFS
4. **Video Fingerprinting**: Add visual fingerprinting for additional verification
5. **Web Interface**: Build user-friendly web app for verification

## ğŸ“„ License

MIT License

## ğŸ¤ Contributing

This is a proof-of-concept for political campaign video verification. Contributions welcome!

---

**Built with:** OpenAI Whisper, Wav2Vec2, Sentence-Transformers, PyTorch

